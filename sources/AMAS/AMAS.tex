\part{Multi-Agents Systems and AMAS Theory}

As we said at the end of the last part, providing a method able to scale to the needs of the full range of optimization problems would require to it to be capable of adapting itself to the problem at hand.
The main theme of the SMAC team\footnote{\emph{Systèmes Multi-Agents Coopératifs} (Cooperative Multi-Agents Systems)}, in which this thesis has been realized, in the Adaptive Multi-Agent Systems (AMAS) Theory. This theory relates to the design of agent-based complex systems with self-adaptive capabilities.

In this part we will present first a short history of multi-agents systems, before concentrating on the concepts of the AMAS theory.

\section{Multi-Agents Systems}

Multi-Agents Systems (MAS) are a relatively recent field which can be seen as the intersection of Artificial Intelligence (AI) and Systems Theory. As a reminder, the AI field was developed in 1950s as "the science and engineering of making intelligent machines." [[source MacCarthy cf wikipedia]] This rather ambitious project was somewhat toned down during the 70s when the field was the subject of several setbacks leading to an "AI winter"[[REF ? Russell and Norvig ?]], which effects can still be felt today. The commonly accepted reason for this setback was that the researchers have been too much ambitious in their expectations of the breakthroughs which would be produced by the field, and did not take enough in account the inherent complexity of some of the task they were proposing to handle (\emph{e.g. language processing}).

[[TO PUT? Several specific subfield subfields of AI have been defined, among which we can find automated problem solving, machine learning, robotics, knowledge engineering, planning, affective computing \emph{etc.}]]

This "disgrace" period of the IA field was ended with the success of expert systems in the 80s. These systems aim to emulate the ability of a human being to take decisions based on expert knowledge, using inference mechanisms (via an \emph{inference engine}) and a rules database.
However, even expert systems cannot avoid the complexity of modeling knowledge, and are still ultimately limited by the growth of their rules database. This concern, among others (such as privacy of informations) lead to a new field of IA named Distributed Artificial Intelligence (DAI)[[REF?]], where several expert systems collaborate to provide a collective diagnostic of a situation.

In parallel to the developments of AI, another field of knowledge emerged in the beginning of the century, Cybernetics (also called System Theory), the study of self-regulating systems. Interestingly, this field had radically different origins from AI, taking root in social and natural sciences. These two disciplines had a somewhat uneasy coexistence for some times during the 50s, after which AI took the lead and cybernetics[[see on the importance of being emergent - Peter Cariani]].The field knew a revival in the 70s with the "new cybernetics", or "second-order cybernetics", which introduces the study of self-organizing systems and the notion of observer.

It is interesting to note the conflicting nature of AI and cybernetics. AI initially based itself the  on the analytical study of knowledge, using symbol manipulation coming from algebra and logics. Cybernetics was part of the more general [[epistemic/epistemological ??]] upheaval of constructivism.

It is a the conjunction of these two seemingly contradictory fields that was born the study of Multi-Agents Systems.

\subsection{Principles of Multi-Agents Systems}

[[Say we concentrate on Problem Solving]]

\subsection{The Adaptive Multi-Agents Systems Theory}

The conception of MAS for problem solving is not an easy endeavor. Suffice to observe that most of the multi-agents systems algorithms dedicated to problem solving proposed by the scientific community are nature-inspired (ants, flocks, bees, bats etc.). Indeed, Nature had a long time to experiment on several arduous problem and a lost of subjects at hand. Why would we not take advantage of that? However, such a strategy presents a severe limitation, as it can bring us existing solutions to apply to potential problems, but ultimately cannot help us to find potential solution to some existing problems. By restricting ourself to nature-inspired mechanisms we are bound to their application field.
The inspiration for the internal combustion engine was not found in nature, as no animal ever bothered with trying to reach for the Moon\footnote{In total honesty, it is possible that some animals tried to reach for the Moon. But it seems such behavior did not give them enough significant evolutionary advantage to be noteworthy (except of course for a specific cow in the popular nursery rhyme [[put a ref ?]]).}.

In order to overcome this limitation, we need to rely on a more theoretical approach which would help us in the conception of MAS for which we do not know any existing applicable mechanisms. Such an approach is provided by the Adaptive Multi-Agents Systems (AMAS) theory.

The AMAS theory was developed by the SMAC team and formalized in \cite{glize2001adaptation} and focus on cooperation as the fundamental mechanism of MAS design.

At the basis of the theory is the modeling of a system as a set of entities, the agents, interacting among themselves and with their environment. This modeling is holonic[[?]] at its core, since the agents themselves can also be viewed as systems for which the environment consists of the other agents as well as the environment of the encompassing system[[TRUE ?]].


The system can be deemed to be \emph{functionally adequate} by an external observer if this latter judges that the system as a whole correctly accomplishes its function in regard of the environment\footnote{It is important to understand that, from a theoretical point of view, the notion of functional adequacy is inherently subjective, and depends on the observer. In practice it is however usually more easier to attain a reasonable consensus. For example a natural system will usually be deemed adequate if it survives and thrives in a sustainable way. For an artificial system it is even easier since the functional adequacy correspond to the function expected by the designer of the system.}.

The AMAS theory then identifies three categories of interactions between a system and its environment (we indicated in parenthesis some analogs found in biological interaction theory [[REF]]) :
\begin{compactitem}
\item Cooperative action: the acting entity is beneficial to the other (mutualism)
\item Antinomic [[?Antagonistic?]] action: the acting entity is detrimental to the other (competition/amensalism)
\item Neutral action: the acting entity has no effect on the other (neutralism/commensalism)
\end{compactitem}

From this categorization, the AMAS theory draws its formal definition of functional adequacy (and fundamental axiom):

\definition{Functional adequacy}{A functionally adequate system has no antinomic[[?]] interaction with its environment}

[[PUT DIAGRAM OF A FUNCTIONALLY ADEQUATE SYSTEM]]

Using this axiom, two fundamental lemma has been demonstrated:

\definition{Lemme 1}{The set of cooperative systems is included in the set of functionally adequate systems}

\definition{Lemme 2}{For all functionally adequate system, there exists a cooperative system which is also functionally adequate in the same environment}