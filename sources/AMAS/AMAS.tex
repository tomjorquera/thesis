\part{Multi-Agents Systems and AMAS Theory}

As we said at the end of the last part, providing a method able to scale to the needs of the full range of optimization problems would require to it to be capable of adapting itself to the problem at hand.
The main theme of the SMAC team\footnote{\emph{Systèmes Multi-Agents Coopératifs} (Cooperative Multi-Agents Systems)}, in which this thesis has been realized, in the Adaptive Multi-Agent Systems (AMAS) Theory. This theory relates to the design of agent-based complex systems with self-adaptive capabilities.

In this part we will present first a short history of multi-agents systems, before concentrating on the concepts of the AMAS theory.

\section{Multi-Agents Systems}

Multi-Agents Systems (MAS) are a relatively recent field which can be seen as the intersection of Artificial Intelligence (AI) and Systems Theory. As a reminder, the AI field was developed in 1950s as "the science and engineering of making intelligent machines." [[source MacCarthy cf wikipedia]] This rather ambitious project was somewhat toned down during the 70s when the field was the subject of several setbacks leading to an "AI winter"[[REF ? Russell and Norvig ?]], which effects can still be felt today. The commonly accepted reason for this setback was that the researchers have been too much ambitious in their expectations of the breakthroughs which would be produced by the field, and did not take enough in account the inherent complexity of some of the task they were proposing to handle (\emph{e.g. language processing}).

[[TO PUT? Several specific subfield subfields of AI have been defined, among which we can find automated problem solving, machine learning, robotics, knowledge engineering, planning, affective computing \emph{etc.}]]

This "disgrace" period of the IA field was ended with the success of expert systems in the 80s. These systems aim to emulate the ability of a human being to take decisions based on expert knowledge, using inference mechanisms (via an \emph{inference engine}) and a rules database.
However, even expert systems cannot avoid the complexity of modeling knowledge, and are still ultimately limited by the growth of their rules database. This concern, among others (such as privacy of informations) lead to a new field of IA named Distributed Artificial Intelligence (DAI)[[REF?]], where several expert systems collaborate to provide a collective diagnostic of a situation.

In parallel to the developments of AI, another field of knowledge emerged in the beginning of the century, Cybernetics (also called System Theory), the study of self-regulating systems. Interestingly, this field had radically different origins from AI, taking root in social and natural sciences. These two disciplines had a somewhat uneasy coexistence for some times during the 50s, after which AI took the lead and cybernetics[[see on the importance of being emergent - Peter Cariani]].The field knew a revival in the 70s with the "new cybernetics", or "second-order cybernetics", which introduces the study of self-organizing systems and the notion of observer.

It is interesting to note the conflicting nature of AI and cybernetics. AI initially based itself the  on the analytical study of knowledge, using symbol manipulation coming from algebra and logics. Cybernetics was part of the more general [[epistemic/epistemological ??]] upheaval of constructivism.

It is in the mists of this contradiction that was born the study of Multi-Agents Systems